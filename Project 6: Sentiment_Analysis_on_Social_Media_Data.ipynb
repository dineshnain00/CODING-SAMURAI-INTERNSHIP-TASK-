{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMvqxIWKYuMc8to/OIqRpvm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dineshnain00/CODING-SAMURAI-INTERNSHIP-TASK-/blob/main/Project%206%3A%20Sentiment_Analysis_on_Social_Media_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hMgwQn-MjP6T"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "#— loads Python's regular expression module (used to find and replace text patterns)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "#— loads pandas (a table/dataframe library) and calls it pd for short."
      ],
      "metadata": {
        "id": "QwDooTI2ja8h"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "#— loads NLTK (Natural Language Toolkit), a common NLP utility library."
      ],
      "metadata": {
        "id": "wZ6O4Hu6jimQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "#— imports VADER, a sentiment tool tuned for short social-media text."
      ],
      "metadata": {
        "id": "5xm1zjWCjqOi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "#— imports TextBlob, a simple library that gives a polarity score for text."
      ],
      "metadata": {
        "id": "A6ZkAwzEjzXF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('vader_lexicon')\n",
        "#— makes sure the VADER word-list is available on your machine (downloads it the first time)."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhf7-O73j6sa",
        "outputId": "ddf7ca6d-dfda-4e03-e5a4-f80cb1f9466a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_tweet(text):\n",
        "   # \"\"\"\n",
        "   # Basic tweet/text cleaning:\n",
        "   # - convert to string & lowercase\n",
        "    #- remove urls, mentions, 'RT', hashes (# symbol), and non-alphanumeric chars\n",
        "  #  - collapse extra spaces\n",
        "   # \"\"\"\n",
        "    text = str(text)\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'http\\S+|www\\.\\S+', '', text)        # remove URLs\n",
        "    text = re.sub(r'@\\w+', '', text)                  # remove mentions\n",
        "    text = re.sub(r'#', '', text)                     # remove the hash symbol but keep the word\n",
        "    text = re.sub(r'\\brt\\b', '', text)                # remove standalone RT\n",
        "    text = re.sub(r'[^a-z0-9\\s]', '', text)           # remove punctuation & emojis (simple approach)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()          # collapse whitespace and trim\n",
        "    return text"
      ],
      "metadata": {
        "id": "wFg3GxEzkOHv"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vader_sentiment(text, analyzer):\n",
        "    scores = analyzer.polarity_scores(text)\n",
        "    compound = scores['compound']\n",
        "    if compound >= 0.05:\n",
        "        label = 'positive'\n",
        "    elif compound <= -0.05:\n",
        "        label = 'negative'\n",
        "    else:\n",
        "        label = 'neutral'\n",
        "    return compound, label\n",
        "\n",
        "def textblob_sentiment(text):\n",
        "    blob = TextBlob(text)\n",
        "    polarity = blob.sentiment.polarity\n",
        "    if polarity > 0.05:\n",
        "        label = 'positive'\n",
        "    elif polarity < -0.05:\n",
        "        label = 'negative'\n",
        "    else:\n",
        "        label = 'neutral'\n",
        "    return polarity, label"
      ],
      "metadata": {
        "id": "tIoOqGN3k9hE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"CyberBullying Comments Dataset.csv\")\n",
        "print(df)\n",
        "#Option B (if you don't have a CSV): use a small sample list\n",
        "tweets = [\"I love this product!\", \"Worst service ever :(\", \"I'm not sure...\"]\n",
        "df = pd.DataFrame({'text': tweets})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJHId9cglfBj",
        "outputId": "54cb5618-1227-4759-fe3a-27d45fc9b609"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                    Text  CB_Label\n",
            "0      damn there is someones nana up here at beach w...         0\n",
            "1      no kidding! dick clark was a corpse mechanical...         0\n",
            "2      i read an article on jobros and thought damn w...         0\n",
            "3      I got one fucking day of sprinkles and now it'...         0\n",
            "4      I was already listening to Elliott smith  and ...         0\n",
            "...                                                  ...       ...\n",
            "11095  \"Don't worry you little empty head over it ......         1\n",
            "11096  \"Some of Ya'll are dumb as fuck.... These are ...         1\n",
            "11097  \"Lana, you're so full of shit your eyes are br...         1\n",
            "11098  \"You ain't lying let the @dbeeio61:disqus\\xa0\\...         1\n",
            "11099  \"Looks like that little Cut-n-paste job has go...         1\n",
            "\n",
            "[11100 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocess text\n",
        "df['clean_text'] = df['text'].apply(clean_tweet)\n",
        "\n",
        "# Initialize the VADER analyzer\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Apply sentiment functions and expand results into columns\n",
        "df[['vader_compound', 'vader_label']] = df['clean_text'].apply(\n",
        "    lambda t: pd.Series(vader_sentiment(t, analyzer))\n",
        ")\n",
        "df[['tb_polarity', 'tb_label']] = df['clean_text'].apply(\n",
        "    lambda t: pd.Series(textblob_sentiment(t))\n",
        ")"
      ],
      "metadata": {
        "id": "ray8sC8XmFfa"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Simple ensemble / final label: if both agree use that, otherwise prefer VADER\n",
        "def combined_label(row):\n",
        "    if row['vader_label'] == row['tb_label']:\n",
        "        return row['vader_label']\n",
        "    return row['vader_label']\n",
        "\n",
        "df['label'] = df.apply(combined_label, axis=1)"
      ],
      "metadata": {
        "id": "jxCCu_IVnLZ9"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary statistics\n",
        "summary_counts = df['label'].value_counts()\n",
        "summary_pct = df['label'].value_counts(normalize=True).mul(100).round(2)\n",
        "\n",
        "print(\"Counts:\\n\", summary_counts)\n",
        "print(\"\\nPercentages:\\n\", summary_pct)\n",
        "\n",
        "# Save results to CSV\n",
        "df.to_csv('tweets_with_sentiment.csv', index=False)"
      ],
      "metadata": {
        "id": "5pO2mqKynUCm",
        "outputId": "6e8d0dc2-c142-4a21-dfdc-c6fffebd1d4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counts:\n",
            " label\n",
            "negative    2\n",
            "positive    1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Percentages:\n",
            " label\n",
            "negative    66.67\n",
            "positive    33.33\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    }
  ]
}